{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, ffmpeg, whisper\n",
    "from pytubefix import YouTube, Stream\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "yt_video_links_file = \"YouTube Video Links.txt\"\n",
    "video_output_path = \"Video\"\n",
    "audio_output_path = \"Audio\"\n",
    "transcription_output_path = \"Transcription\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(filename: str) -> str:\n",
    "    # Escape Double Quotes\n",
    "    filename = filename.replace('\"', '\\\\\"')\n",
    "\n",
    "    # Replace Invalid Characters with '_'\n",
    "    invalid_chars = re.compile(r'[<>:\"/\\\\|?*]')\n",
    "    sanitized_filename = invalid_chars.sub('_', filename)\n",
    "\n",
    "    return sanitized_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data (YouTube Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def download_youtube_video(video_filename: str, stream: Stream) -> tuple[str, str]:\n",
    "    # Create Video Directory\n",
    "    os.makedirs(video_output_path, exist_ok=True)\n",
    "    \n",
    "    # Set Path for Video File\n",
    "    video_file = os.path.join(video_output_path, video_filename)\n",
    "    \n",
    "    # Delete Old Existing Video File (note: to clean any corrupted file)\n",
    "    if os.path.exists(video_file):\n",
    "        os.remove(video_file)\n",
    "        \n",
    "    # Download Video File\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    print(f'Downloading (Video): {video_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    stream.download(output_path=video_output_path, filename=video_filename)\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    \n",
    "    # Return Video File and Name\n",
    "    return video_file, video_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Extraction (Video to Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_file: str, video_filename: str) -> tuple[str, str]:\n",
    "    # Create the Audio Directory\n",
    "    os.makedirs(audio_output_path, exist_ok=True)\n",
    "\n",
    "    # Set Audio File Name (\".mp3\")\n",
    "    audio_filename = f'{os.path.splitext(video_filename)[0]}.mp3'\n",
    "\n",
    "    # Set Path for Audio File\n",
    "    audio_file = os.path.join(audio_output_path, audio_filename)\n",
    "    \n",
    "    # Delete Old Existing Audio File (note: to clean any corrupted file)\n",
    "    if os.path.exists(audio_file):\n",
    "        os.remove(audio_file)\n",
    "    \n",
    "    # Extract Audio File\n",
    "    print(f'Extracting (Audio): {audio_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    (\n",
    "        ffmpeg\n",
    "        .input(video_file)\n",
    "        .output(audio_file, format='mp3', acodec='libmp3lame', loglevel=\"info\")\n",
    "        .run(overwrite_output=True)\n",
    "    )\n",
    "    \n",
    "    # Return Audio File and Name\n",
    "    return audio_file, audio_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription (Audio to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_file: str, audio_filename: str, index: int):\n",
    "    # Create the Transcription Directory\n",
    "    os.makedirs(transcription_output_path, exist_ok=True)\n",
    "    \n",
    "    # Set Transcription File Name (\"[index]....txt\")\n",
    "    transcription_filename = f'[{index}] {os.path.splitext(audio_filename)[0]}.txt'\n",
    "    \n",
    "    # Set Path for Transcription File\n",
    "    transcription_file = os.path.join(transcription_output_path, transcription_filename)\n",
    "    \n",
    "    # Delete Old Existing Transcription File (note: to clean any corrupted file)\n",
    "    if os.path.exists(transcription_file):\n",
    "        os.remove(transcription_file)\n",
    "    \n",
    "    # Get/Download OpenAI Whisper Model\n",
    "    \"\"\" \n",
    "        Models: \n",
    "            tiny, base, small, medium, large, turbo\n",
    "        English-Only:\n",
    "            tiny.en, base.en, small.en, medium.en\n",
    "        \n",
    "        Required VRAM:            Speed (same with .en):\n",
    "            1) 1GB - tiny, base       1) 10x - tiny\n",
    "            2) 2GB - small            2) 8x - turbo\n",
    "            3) 5GB - medium           3) 7x - base\n",
    "            4) 6GB - turbo            4) 4x - small\n",
    "            5) 10GB - large           5) 2x - medium\n",
    "                                      6) 1x - large\n",
    "        \n",
    "        Quote from OpenAI: \n",
    "          - The .en models for English-only applications tend to perform better, especially for the tiny.en and base.en models.\n",
    "            We observed that the difference becomes less significant for the small.en and medium.en models.\n",
    "        \n",
    "        Note: 4GB lang VRAM sakin kaya small.en\n",
    "    \"\"\"  \n",
    "    print(f'Transcribing (Text): {transcription_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    model = whisper.load_model(\"small.en\", device=device)\n",
    "\n",
    "    # Transcribe Audio File\n",
    "    result = model.transcribe(audio_file, fp16=False, verbose=False)\n",
    "    with open(transcription_file, 'w') as f:\n",
    "        f.write(result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38853f382e634b4a90cd0b8da83ee291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting YouTube URLs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading (Video): Arizona Gen Z voters sit down to talk 2024 election.mp4\n",
      "\n",
      " ↳ |██████████████████████████████████████████████████████████████████| 100.0%\n",
      "\n",
      "Extracting (Audio): Arizona Gen Z voters sit down to talk 2024 election.mp3\n",
      "\n",
      "Transcribing (Text): [0] Arizona Gen Z voters sit down to talk 2024 election.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                    | 0/46755 [00:00<?, ?frames/s]\u001b[A\n",
      "  5%|███▊                                                                    | 2448/46755 [00:06<01:55, 384.85frames/s]\u001b[A\n",
      " 11%|███████▊                                                                | 5080/46755 [00:12<01:44, 400.43frames/s]\u001b[A\n",
      " 17%|████████████▍                                                           | 8072/46755 [00:23<01:56, 331.98frames/s]\u001b[A\n",
      " 23%|████████████████▍                                                      | 10856/46755 [00:32<01:52, 319.63frames/s]\u001b[A\n",
      " 28%|████████████████████                                                   | 13224/46755 [00:40<01:45, 316.50frames/s]\u001b[A\n",
      " 34%|████████████████████████▍                                              | 16056/46755 [00:48<01:34, 325.89frames/s]\u001b[A\n",
      " 41%|████████████████████████████▊                                          | 18936/46755 [00:57<01:24, 327.93frames/s]\u001b[A\n",
      " 46%|████████████████████████████████▋                                      | 21520/46755 [01:05<01:18, 322.18frames/s]\u001b[A\n",
      " 51%|████████████████████████████████████▍                                  | 23984/46755 [01:12<01:09, 329.59frames/s]\u001b[A\n",
      " 57%|████████████████████████████████████████▊                              | 26864/46755 [01:20<00:58, 337.71frames/s]\u001b[A\n",
      " 63%|████████████████████████████████████████████▌                          | 29344/46755 [01:29<00:53, 323.32frames/s]\u001b[A\n",
      " 68%|████████████████████████████████████████████████▌                      | 32000/46755 [01:36<00:44, 329.10frames/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████▍                  | 34568/46755 [01:43<00:36, 337.02frames/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████              | 37544/46755 [01:52<00:27, 335.79frames/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████▋          | 39936/46755 [01:59<00:20, 339.18frames/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████▌      | 42520/46755 [02:08<00:12, 331.21frames/s]\u001b[A\n",
      " 97%|████████████████████████████████████████████████████████████████████▋  | 45264/46755 [02:16<00:04, 327.85frames/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████| 46755/46755 [02:21<00:00, 329.56frames/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading (Video): Michigan’s Muslims Helped Biden Win in 2020. Will They Back Harris in Nov._ _ Amanpour and Company.mp4\n",
      "\n",
      " ↳ |██████████████████████████████████████████████████████████████████| 100.0%\n",
      "\n",
      "Extracting (Audio): Michigan’s Muslims Helped Biden Win in 2020. Will They Back Harris in Nov._ _ Amanpour and Company.mp3\n",
      "\n",
      "Transcribing (Text): [1] Michigan’s Muslims Helped Biden Win in 2020. Will They Back Harris in Nov._ _ Amanpour and Company.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                   | 0/111430 [00:00<?, ?frames/s]\u001b[A\n",
      "  3%|█▊                                                                     | 2900/111430 [00:07<04:49, 375.27frames/s]\u001b[A\n",
      "  5%|███▋                                                                   | 5784/111430 [00:17<05:22, 327.34frames/s]\u001b[A\n",
      "  8%|█████▌                                                                 | 8690/111430 [00:27<05:36, 305.74frames/s]\u001b[A\n",
      " 10%|███████▏                                                              | 11462/111430 [00:37<05:32, 301.00frames/s]\u001b[A\n",
      " 13%|█████████                                                             | 14390/111430 [00:46<05:21, 301.93frames/s]\u001b[A\n",
      " 16%|██████████▉                                                           | 17362/111430 [00:56<05:06, 307.38frames/s]\u001b[A\n",
      " 18%|████████████▌                                                         | 20004/111430 [01:04<05:00, 303.86frames/s]\u001b[A\n",
      " 20%|██████████████▏                                                       | 22616/111430 [01:13<04:51, 304.24frames/s]\u001b[A\n",
      " 23%|████████████████                                                      | 25568/111430 [01:23<04:43, 302.71frames/s]\u001b[A\n",
      " 25%|█████████████████▋                                                    | 28172/111430 [01:31<04:32, 305.06frames/s]\u001b[A\n",
      " 28%|███████████████████▌                                                  | 31152/111430 [01:40<04:12, 318.47frames/s]\u001b[A\n",
      " 31%|█████████████████████▍                                                | 34148/111430 [01:49<04:05, 315.03frames/s]\u001b[A\n",
      " 33%|███████████████████████▎                                              | 37120/111430 [01:59<04:00, 308.95frames/s]\u001b[A\n",
      " 36%|█████████████████████████▏                                            | 40080/111430 [02:09<03:52, 306.53frames/s]\u001b[A\n",
      " 38%|██████████████████████████▊                                           | 42716/111430 [02:18<03:41, 309.84frames/s]\u001b[A\n",
      " 41%|████████████████████████████▋                                         | 45598/111430 [02:26<03:28, 316.33frames/s]\u001b[A\n",
      " 43%|██████████████████████████████▎                                       | 48272/111430 [02:36<03:29, 301.51frames/s]\u001b[A\n",
      " 46%|███████████████████████████████▉                                      | 50828/111430 [02:44<03:17, 307.48frames/s]\u001b[A\n",
      " 48%|█████████████████████████████████▊                                    | 53772/111430 [02:53<03:04, 311.70frames/s]\u001b[A\n",
      " 51%|███████████████████████████████████▌                                  | 56686/111430 [03:03<02:58, 306.49frames/s]\u001b[A\n",
      " 54%|█████████████████████████████████████▍                                | 59628/111430 [03:13<02:49, 305.29frames/s]\u001b[A\n",
      " 56%|███████████████████████████████████████▎                              | 62602/111430 [03:23<02:41, 301.74frames/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████                             | 65306/111430 [03:31<02:29, 307.90frames/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████▊                           | 68078/111430 [03:40<02:18, 313.26frames/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████▍                         | 70790/111430 [03:49<02:13, 305.35frames/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████                        | 73346/111430 [03:58<02:07, 299.67frames/s]\u001b[A\n",
      " 68%|███████████████████████████████████████████████▉                      | 76238/111430 [04:08<01:57, 298.70frames/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████▋                    | 79134/111430 [04:16<01:44, 310.17frames/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████▎                  | 81730/111430 [04:24<01:34, 314.23frames/s]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████▉                 | 84334/111430 [04:33<01:28, 306.06frames/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████▋               | 87098/111430 [04:42<01:18, 309.89frames/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████▍             | 89890/111430 [04:51<01:09, 309.46frames/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████            | 92518/111430 [05:01<01:03, 296.75frames/s]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████▊          | 95270/111430 [05:10<00:55, 293.49frames/s]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████▋        | 98118/111430 [05:19<00:43, 304.69frames/s]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████▌      | 100946/111430 [05:28<00:33, 311.95frames/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████▉     | 103294/111430 [05:36<00:26, 301.79frames/s]\u001b[A\n",
      " 95%|█████████████████████████████████████████████████████████████████▋   | 106150/111430 [05:45<00:16, 311.54frames/s]\u001b[A\n",
      " 98%|███████████████████████████████████████████████████████████████████▎ | 108794/111430 [05:54<00:08, 305.95frames/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████| 111430/111430 [06:00<00:00, 309.21frames/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading (Video): The ‘battleground state’ of Pennsylvania is most important in US presidential election.mp4\n",
      "\n",
      " ↳ |██████████████████████████████████████████████████████████████████| 100.0%\n",
      "\n",
      "Extracting (Audio): The ‘battleground state’ of Pennsylvania is most important in US presidential election.mp3\n",
      "\n",
      "Transcribing (Text): [2] The ‘battleground state’ of Pennsylvania is most important in US presidential election.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                    | 0/32589 [00:00<?, ?frames/s]\u001b[A\n",
      "  9%|██████▏                                                                 | 2808/32589 [00:09<01:43, 287.18frames/s]\u001b[A\n",
      " 18%|████████████▋                                                           | 5768/32589 [00:18<01:26, 308.82frames/s]\u001b[A\n",
      " 26%|██████████████████▉                                                     | 8572/32589 [00:29<01:22, 290.81frames/s]\u001b[A\n",
      " 35%|████████████████████████▌                                              | 11256/32589 [00:36<01:08, 312.42frames/s]\u001b[A\n",
      " 43%|██████████████████████████████▊                                        | 14124/32589 [00:43<00:54, 340.65frames/s]\u001b[A\n",
      " 52%|████████████████████████████████████▉                                  | 16948/32589 [00:52<00:46, 334.82frames/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████▌                            | 19516/32589 [01:00<00:39, 334.44frames/s]\u001b[A\n",
      " 69%|█████████████████████████████████████████████████                      | 22512/32589 [01:08<00:29, 341.86frames/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████▏               | 25328/32589 [01:16<00:21, 341.14frames/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████▏         | 28068/32589 [01:26<00:13, 326.70frames/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████▊    | 30684/32589 [01:35<00:06, 314.90frames/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████| 32589/32589 [01:42<00:00, 317.63frames/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "yt_urls = []\n",
    "with open(yt_video_links_file, \"r\") as file:\n",
    "    yt_urls = list(set(url.strip() for url in file.readlines() if url.strip()))\n",
    "\n",
    "with tqdm(total=len(yt_urls), desc=\"Getting YouTube URLs\") as pbar:\n",
    "    for index, url in enumerate(yt_urls):\n",
    "        current = f\"[{index+1}/{len(yt_urls)}]\"\n",
    "                \n",
    "        # Get Video Information\n",
    "        yt = YouTube(url, on_progress_callback=on_progress)\n",
    "        stream = yt.streams.get_audio_only()\n",
    "\n",
    "        # Sanitize Video File Name\n",
    "        video_filename = sanitize_filename(stream.default_filename)\n",
    "        \n",
    "        # Get Native File Name Without Extension (e.g., \".mp4\")\n",
    "        native_transcription_filename = f'{os.path.splitext(video_filename)[0]}.txt'\n",
    "        \n",
    "        # Skip If Transcription Already Exists\n",
    "        transcription_exists = False\n",
    "        pbar.set_description(f\"Checking Existing Transcription File {current}\")\n",
    "        if os.path.exists(transcription_output_path):\n",
    "            for existing_transcription_filename in os.listdir(transcription_output_path):\n",
    "                existing_native_transcription_filename = re.sub(r'^\\[\\d+\\]\\s+', '', existing_transcription_filename)\n",
    "                if existing_native_transcription_filename == native_transcription_filename:\n",
    "                    existing_transcription_path = os.path.join(transcription_output_path, existing_transcription_filename)\n",
    "                    if os.path.exists(existing_transcription_path):\n",
    "                        transcription_exists = True\n",
    "        if transcription_exists:\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        # Download YouTube Video\n",
    "        pbar.set_description(f\"Downloading (Video) {current}\")\n",
    "        video_file, video_filename = download_youtube_video(video_filename, stream)\n",
    "        \n",
    "        # Extract Audio from Video -> Delete Video File\n",
    "        pbar.set_description(f\"Extracting (Audio) {current}\")\n",
    "        audio_file, audio_filename = extract_audio_from_video(video_file, video_filename)\n",
    "        os.remove(video_file)\n",
    "        \n",
    "        # Transcribe Audio to Text -> Delete Audio File\n",
    "        pbar.set_description(f\"Transcribing (Text) {current}\")\n",
    "        transcribe_audio(audio_file, audio_filename, index)\n",
    "        os.remove(audio_file)\n",
    "        \n",
    "        pbar.update(1)\n",
    "    pbar.set_description(\"Finished Data Gathering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning: Topic Modeling and Sentence Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sentiment Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Sentiment Analysis with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation: Hyperparameter Tuning and Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
