{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f43d36-c3e9-4c80-8d42-e82659a06a2f",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efd7c4-42c6-45f5-bbc0-ba8fa0663d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy, torch, itertools\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde1b65-d8a9-45aa-9e07-b794a9cfe54b",
   "metadata": {},
   "source": [
    "# Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39484717-540e-48c1-8b54-60ffaf3bb002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset (CSV) Column Names\n",
    "sentence_column_name = \"Sentences\"\n",
    "sentiment_column_name = \"Final_Sent\"\n",
    "final_dataset_folder_name = os.path.join('..', '4) Sentiment Annotation')\n",
    "model_evaluation_result_folder_name = os.path.join(\"Model Results and Actual Data\", \"BERT\")\n",
    "os.makedirs(model_evaluation_result_folder_name, exist_ok=True)\n",
    "\n",
    "# To Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472b961-eb88-4c39-959e-ca490fb12f25",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Splitting (Keep Same Data for Both Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2d9f2-42d0-4718-a280-18165e90d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(final_dataset_folder_name, exist_ok=True)\n",
    "    \n",
    "    # Define file paths\n",
    "    train_path = os.path.join(final_dataset_folder_name, 'train.csv')\n",
    "    val_path = os.path.join(final_dataset_folder_name, 'validation.csv')\n",
    "    test_path = os.path.join(final_dataset_folder_name, 'test.csv')\n",
    "    \n",
    "    # Check if split files already exist\n",
    "    if all(os.path.exists(f) for f in [train_path, val_path, test_path]):\n",
    "        train = pd.read_csv(train_path)\n",
    "        val = pd.read_csv(val_path)\n",
    "        test = pd.read_csv(test_path)\n",
    "        \n",
    "        # Combine DataFrames vertically\n",
    "        df = train.append([val, test], ignore_index=True)\n",
    "        \n",
    "        return train, val, test, df\n",
    "    else:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(os.path.join(final_dataset_folder_name, 'final_dataset.csv'))\n",
    "        \n",
    "        # Split data into 80% training+validation and 20% test\n",
    "        remaining, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        # Split the remaining 80% into 70% training and 10% validation (0.125 of 80% = 10% overall)\n",
    "        train, val = train_test_split(remaining, test_size=0.125, random_state=42)\n",
    "        \n",
    "        # Save splits\n",
    "        train.to_csv(train_path, index=False)\n",
    "        val.to_csv(val_path, index=False)\n",
    "        test.to_csv(test_path, index=False)\n",
    "    \n",
    "        return train, val, test, df\n",
    "\n",
    "train, val, test, full = split_data()\n",
    "\n",
    "train, val, test, full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cda003-ed9e-4bfe-8f96-529f0d7e681d",
   "metadata": {},
   "source": [
    "# Computing Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93974fb-7a73-40ce-86f1-ec6a718ef6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(labels):\n",
    "    # Shift labels for model [-1, 0, 1] to [0, 1, 2]\n",
    "    mapped_labels = labels + 1\n",
    "    # Count how many samples we have of each class\n",
    "    class_counts = np.bincount(mapped_labels)\n",
    "    # Give higher weights to classes with fewer samples\n",
    "    weights = 1. / class_counts\n",
    "    # Normalize weights to sum to number of classes\n",
    "    weights = weights * len(class_counts) / weights.sum()\n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "# Calculate weights for each class from training data\n",
    "class_weights = compute_class_weights(train[sentiment_column_name].values)\n",
    "class_weights = class_weights.to(device)  # Move weights to GPU if available\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950c5dc-4c0f-4a2e-807c-49057eff9729",
   "metadata": {},
   "source": [
    "# Configure Model and Tokenizer (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe13256-c790-4a57-834e-a8585c1a2d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base BERT model to use\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# Create a custom BERT model that can handle weighted loss\n",
    "class BertWithWeightedLoss(BertForSequenceClassification):\n",
    "    def __init__(self, config, class_weights):\n",
    "        super().__init__(config)\n",
    "        self.class_weights = class_weights # Store class weights for loss calculation\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Get model outputs without computing loss\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=None # Set to None to prevent automatic loss calculation\n",
    "        )\n",
    "        \n",
    "        # Calculate weighted loss if labels are provided (training phase)\n",
    "        if labels is not None:\n",
    "            # Create loss function with class weights\n",
    "            loss_fct = CrossEntropyLoss(weight=self.class_weights)\n",
    "            # Calculate loss using model predictions and true labels\n",
    "            loss = loss_fct(\n",
    "                outputs.logits.view(-1, self.num_labels),  # Reshape predictions\n",
    "                labels.view(-1)                            # Reshape labels\n",
    "            )\n",
    "            outputs.loss = loss  # Add loss to outputs\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# Initialize the tokenizer that will convert text to numbers\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d6740-175b-4c24-8488-81e428d45502",
   "metadata": {},
   "source": [
    "# Define Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac60c60-8317-4241-9c80-745a5d9ef956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_data, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a copy of eval_data to avoid modifying the original\n",
    "    results_df = eval_data.copy()\n",
    "    # Add new column for predictions\n",
    "    results_df['Predicted_Sent'] = None\n",
    "        \n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(results_df.iterrows(), total=len(results_df), desc=\"Evaluating\"):\n",
    "            # Tokenize single sentence\n",
    "            encoding = tokenizer(\n",
    "                row[sentence_column_name],\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Move inputs to device\n",
    "            input_ids = encoding['input_ids'].to(device)\n",
    "            attention_mask = encoding['attention_mask'].to(device)\n",
    "            label = torch.tensor([row[sentiment_column_name]]).to(device)\n",
    "            adjusted_label = label + 1\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(input_ids, attention_mask, labels=adjusted_label)\n",
    "            val_loss += outputs.loss.item()\n",
    "            \n",
    "            # Get prediction\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            pred = (predicted - 1).cpu().numpy()[0]\n",
    "            \n",
    "            # Store prediction in DataFrame\n",
    "            results_df.at[idx, 'Predicted_Sent'] = int(pred)\n",
    "            \n",
    "            # Store for metrics calculation\n",
    "            all_preds.append(pred)\n",
    "            all_labels.append(row[sentiment_column_name])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        'loss': val_loss / len(results_df),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1-score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a01fbd-7d6b-4129-97a0-7835b0392d72",
   "metadata": {},
   "source": [
    "# Define Model Training and Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16dc4b9-41cd-4383-b480-d9d5cb303c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_data, device, epochs, learning_rate):\n",
    "    # Initialize optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    val_metrics = None\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    val_accuracy = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # Set model to training mode\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Process each batch\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} Training\")\n",
    "        for batch in pbar:\n",
    "            # Move batch to GPU if available\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            adjusted_labels = labels + 1 # Shift labels for model [-1, 0, 1] to [0, 1, 2]\n",
    "\n",
    "            # Training step\n",
    "            optimizer.zero_grad() # Clear previous gradients\n",
    "            outputs = model(input_ids, attention_mask, labels=adjusted_labels) # Forward pass\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item() # Accumulate loss\n",
    "\n",
    "            # Update model weights\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "\n",
    "            # Update progress bar with current loss\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculate training loss for this epoch\n",
    "        current_train_loss = total_loss / len(train_loader)\n",
    "        train_loss.append(current_train_loss)\n",
    "\n",
    "        # Calculate validation loss and accuracy for this epoch\n",
    "        val_metrics, _ = evaluate_model(model, val_data, device)\n",
    "        val_loss.append(val_metrics['loss'])\n",
    "        val_accuracy.append(val_metrics['accuracy'])\n",
    "\n",
    "        print(f'Training loss: {current_train_loss}')\n",
    "        print(f'Validation metric: {val_metrics}')\n",
    "    \n",
    "    return model, {\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9185049-d8f1-4308-bc4d-7a36c4a8018f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Model Training with Hyperparameters Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f662c91-5ce7-4d94-aa27-c4f1c9e60e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Batch Text Data\n",
    "def create_data_loader(data, tokenizer, batch_size):\n",
    "    # Create a copy of data to avoid modifying the original\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Convert text to BERT input format with progress bar\n",
    "    encodings = tokenizer(\n",
    "        data_copy[sentence_column_name].tolist(), # Convert sentences to list\n",
    "        truncation=True, # Cut texts longer than max_length\n",
    "        padding=True, # Pad texts shorter than max_length\n",
    "        max_length=128, # Maximum sequence length\n",
    "        return_tensors='pt', # Return PyTorch tensors\n",
    "        verbose=True # Show progress\n",
    "    )\n",
    "\n",
    "    # Create dataset by combining inputs and labels\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        encodings['input_ids'], # Tokenized text\n",
    "        encodings['attention_mask'], # Attention mask for padding\n",
    "        torch.tensor(data_copy[sentiment_column_name].tolist()) # Labels\n",
    "    )\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Function to Train Model with Specific Hyperparameters\n",
    "def train_model_with_hyperparameters(params, train_data, val_data, device, class_weights):\n",
    "    print(f\"Parameters: {params}\")\n",
    "\n",
    "    # Create data loaders with current batch size\n",
    "    train_loader = create_data_loader(train_data, tokenizer, params['batch_size'])\n",
    "\n",
    "    # Initialize the custom BERT model\n",
    "    model = BertWithWeightedLoss.from_pretrained(\n",
    "        model_name,\n",
    "        # Configure BERT for classification\n",
    "        config=BertForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=3,\n",
    "            output_attentions=False, # Don't output attention weights\n",
    "            output_hidden_states=False, # Don't output hidden states\n",
    "        ).config,\n",
    "        class_weights=class_weights\n",
    "    )\n",
    "    # Move model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    # Train model with current parameters\n",
    "    model, train_metric_seq = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_data,\n",
    "        device,\n",
    "        params['epochs'],\n",
    "        params['learning_rate']\n",
    "    )\n",
    "    \n",
    "    return model, train_metric_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea384805-1b03-4d6f-88d2-ccfbd4788aab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb3baed1-07a5-4a81-8871-d29773eb2429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying parameters: {'learning_rate': 2e-05, 'epochs': 3, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertWithWeightedLoss were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\MSI Laptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/3 Training: 100%|████████████████████████████████████████████████| 252/252 [19:16<00:00,  4.59s/it, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average training loss: 0.8366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████████████████████████████████████████████████████████████████| 36/36 [00:32<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'loss': 0.7976726690928141, 'accuracy': 0.6608695652173913, 'precision': 0.6733385716780164, 'recall': 0.6608695652173913, 'f1': 0.6566915358888604}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 Training: 100%|█████████████████████████████████████████████████| 252/252 [19:12<00:00,  4.57s/it, loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Average training loss: 0.5353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████████████████████████████████████████████████████████████████| 36/36 [00:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'loss': 0.7761238022810883, 'accuracy': 0.6852173913043478, 'precision': 0.6838237676923322, 'recall': 0.6852173913043478, 'f1': 0.6834893133780899}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 Training: 100%|███████████████████████████████████████████████| 252/252 [19:12<00:00,  4.57s/it, loss=0.0473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Average training loss: 0.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████████████████████████████████████████████████████████████████| 36/36 [00:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'loss': 0.9791919423474206, 'accuracy': 0.6921739130434783, 'precision': 0.6870751794133023, 'recall': 0.6921739130434783, 'f1': 0.6885514413949225}\n",
      "\n",
      "Parameters: {'learning_rate': 2e-05, 'epochs': 3, 'batch_size': 16}\n",
      "Validation metrics: {'loss': 0.9791919423474206, 'accuracy': 0.6921739130434783, 'precision': 0.6870751794133023, 'recall': 0.6921739130434783, 'f1': 0.6885514413949225}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(BertWithWeightedLoss(\n",
       "   (bert): BertModel(\n",
       "     (embeddings): BertEmbeddings(\n",
       "       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (token_type_embeddings): Embedding(2, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): BertEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0-11): 12 x BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSdpaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (pooler): BertPooler(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (activation): Tanh()\n",
       "     )\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       " ),\n",
       " {'train_loss': 0.5597663093259726,\n",
       "  'val_loss': 0.8509961379071077,\n",
       "  'val_accuracy': 0.6794202898550724})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model using different values to try for each hyperparameters\n",
    "params = {\n",
    "    'hyperparameter_id': 1,\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 2,\n",
    "    'batch_size': 16\n",
    "}\n",
    "model, train_metric_seq = train_model_with_hyperparameters(params, train, val, device, class_weights)\n",
    "\n",
    "# Create Hyperparameter Directory\n",
    "model_evaluation_result_folder_name = os.path.join(model_evaluation_result_folder_name, f'Hyperparameter-{params['hyperparameter_id']}')\n",
    "os.makedirs(model_evaluation_result_folder_name, exist_ok=True)\n",
    "\n",
    "# Name of Parameters as Filename\n",
    "file_name = f'LR {params['learning_rate']}, E {params['epochs']}, BS {params['batch_size']}'\n",
    "\n",
    "# Save the model\n",
    "model_folder_name = os.path.join(model_evaluation_result_folder_name, f'{file_name} - Model')\n",
    "model.save_pretrained(model_folder_name)\n",
    "tokenizer.save_pretrained(model_folder_name)\n",
    "\n",
    "train_metric_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cb645-9ec6-460a-94cd-a3f912dc4ae4",
   "metadata": {},
   "source": [
    "# Model Validation and Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00df7a16-c782-4f75-842e-0e1ba82cdc6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████| 5745/5745 [04:19<00:00, 22.11it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameters: {params}\")\n",
    "\n",
    "# Evaluation on Test Set\n",
    "test_metrics, predicted_labels_df = evaluate_model(model, test, device)\n",
    "_, full_predicted_labels_df = evaluate_model(model, full, device)\n",
    "\n",
    "# Save Validation Metrics\n",
    "metric_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Validation Metric.csv'\n",
    ")\n",
    "pd.DataFrame(train_metric_seq).to_csv(metric_results_file_name, index=False)\n",
    "\n",
    "# Save Test Metrics\n",
    "metric_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Test Metric.csv'\n",
    ")\n",
    "pd.DataFrame([test_metrics]).to_csv(metric_results_file_name, index=False)\n",
    "\n",
    "# Save Predicted Labels\n",
    "sentiment_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Predicted Dataset.csv'\n",
    ")\n",
    "predicted_labels_df.to_csv(sentiment_results_file_name, index=False)\n",
    "\n",
    "# Save Full Predicted Labels\n",
    "full_sentiment_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Full Predicted Dataset.csv'\n",
    ")\n",
    "full_predicted_labels_df.to_csv(full_sentiment_results_file_name, index=False)\n",
    "\n",
    "print(f\"Test set metrics: {test_metrics}\")\n",
    "predicted_labels_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
