{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a644fa66-2070-48ec-bf8b-8c4d09accf3d",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b0e064-a09e-4c5b-a2d4-0b355477bab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, copy, torch, itertools\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265be12-f694-423d-83dc-f456bcbbbf44",
   "metadata": {},
   "source": [
    "# Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d6e654-7786-4a8d-9db3-791f06a065f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset (CSV) Column Names\n",
    "sentence_column_name = \"Sentences\"\n",
    "sentiment_column_name = \"Final_Sent\"\n",
    "final_dataset_folder_name = os.path.join('..', '4) Sentiment Annotation')\n",
    "model_evaluation_result_folder_name = os.path.join(\"Model Results and Actual Data\", \"BERT\")\n",
    "os.makedirs(model_evaluation_result_folder_name, exist_ok=True)\n",
    "\n",
    "# To Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06de5ee-459a-414a-8572-7868dfd73d2d",
   "metadata": {},
   "source": [
    "# Data Splitting (Keep Same Data for Both Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c103e29f-dc5a-4762-9450-04238b6f2981",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                              Sentences  \\\n",
       " 3394  Nate Silver's Bolton has Kamala Harris leading...   \n",
       " 5118  This razor-thin margin demonstrates that Penns...   \n",
       " 2269                            Trump leads by just 1%.   \n",
       " 3190  How critical is winning the state of Michigan ...   \n",
       " 4216  Am I saying Trump's going to win it by 21 poin...   \n",
       " ...                                                 ...   \n",
       " 1282       Kamala Harris, I believe, fits all of those.   \n",
       " 5520  This idea that she's going to magically do bet...   \n",
       " 3963  It holds 15 electoral votes and it is very muc...   \n",
       " 3086  Harris holds narrow leads in four critical bat...   \n",
       " 2805  And so, I refuse a meeting with Donald Trump o...   \n",
       " \n",
       "      Presidential_Candidate         State  Final_Sent  \n",
       " 3394          Kamala Harris      Michigan           1  \n",
       " 5118           Donald Trump  Pennsylvania           1  \n",
       " 2269           Donald Trump      Michigan           1  \n",
       " 3190          Kamala Harris      Michigan           0  \n",
       " 4216           Donald Trump  Pennsylvania           0  \n",
       " ...                     ...           ...         ...  \n",
       " 1282          Kamala Harris       Arizona           1  \n",
       " 5520          Kamala Harris  Pennsylvania           0  \n",
       " 3963          Kamala Harris      Michigan           0  \n",
       " 3086          Kamala Harris      Michigan           1  \n",
       " 2805           Donald Trump      Michigan          -1  \n",
       " \n",
       " [4021 rows x 4 columns],\n",
       "                                               Sentences  \\\n",
       " 5072  And if Trump is really winning Pennsylvania, d...   \n",
       " 2068  Republican voters are increasingly expressing ...   \n",
       " 2301                        They know what he has done.   \n",
       " 2484         You do have Trump sitting plus point five.   \n",
       " 4200  And she is actually changing her mind on a lot...   \n",
       " ...                                                 ...   \n",
       " 3120  So I see a lot of signs that polling is not pi...   \n",
       " 2047                    Right now, Trump might get 50%.   \n",
       " 858   So you think Trump probably does have an advan...   \n",
       " 692   Trump has a lot of issues that I wouldn't pref...   \n",
       " 5686  Trump, a master of using personal narratives t...   \n",
       " \n",
       "      Presidential_Candidate         State  Final_Sent  \n",
       " 5072           Donald Trump  Pennsylvania          -1  \n",
       " 2068           Donald Trump      Michigan          -1  \n",
       " 2301           Donald Trump      Michigan           1  \n",
       " 2484           Donald Trump      Michigan           1  \n",
       " 4200          Kamala Harris  Pennsylvania           0  \n",
       " ...                     ...           ...         ...  \n",
       " 3120          Kamala Harris      Michigan          -1  \n",
       " 2047           Donald Trump      Michigan           0  \n",
       " 858            Donald Trump       Arizona           1  \n",
       " 692            Donald Trump       Arizona           0  \n",
       " 5686           Donald Trump  Pennsylvania          -1  \n",
       " \n",
       " [575 rows x 4 columns],\n",
       "                                               Sentences  \\\n",
       " 4015  And the campaign has had a robust public relat...   \n",
       " 1086              Concrete plans, that's who Kamala is.   \n",
       " 1632  What Kamala and her radical left cronies have ...   \n",
       " 3378  Also, essentially, they see Kamala Harris as s...   \n",
       " 1175                  She's she's behind by two points.   \n",
       " ...                                                 ...   \n",
       " 1891  So and also I do think Harris has some room to...   \n",
       " 4572  She's probably done because that's supposed to...   \n",
       " 1374  Does the Harris walls ticket benefit from that...   \n",
       " 677   I will never be a Republican, but if I were he...   \n",
       " 1297  So I think people are waking up more so than w...   \n",
       " \n",
       "      Presidential_Candidate         State  Final_Sent  \n",
       " 4015          Kamala Harris  Pennsylvania           0  \n",
       " 1086          Kamala Harris       Arizona           1  \n",
       " 1632          Kamala Harris       Arizona          -1  \n",
       " 3378          Kamala Harris      Michigan          -1  \n",
       " 1175          Kamala Harris       Arizona          -1  \n",
       " ...                     ...           ...         ...  \n",
       " 1891          Kamala Harris       Arizona           1  \n",
       " 4572          Kamala Harris  Pennsylvania           0  \n",
       " 1374          Kamala Harris       Arizona           1  \n",
       " 677            Donald Trump       Arizona          -1  \n",
       " 1297          Kamala Harris       Arizona           0  \n",
       " \n",
       " [1149 rows x 4 columns],\n",
       "                                               Sentences  \\\n",
       " 0     This is not good, you're doing something wrong...   \n",
       " 1     Like straight the **** up, you see what he wan...   \n",
       " 2     We don't gotta talk about what he wanna do cau...   \n",
       " 3     But hey, Republican speaking now against the R...   \n",
       " 4          I think Trump go weird because I don't know.   \n",
       " ...                                                 ...   \n",
       " 5740  This is one of the many reasons why I'm voting...   \n",
       " 5741  Not just because of that, but because also she...   \n",
       " 5742  What a breath of fresh air that Kamala Harris ...   \n",
       " 5743  But I am reviewing my plans this weekend for t...   \n",
       " 5744  And Kamala Harris has been preparing her whole...   \n",
       " \n",
       "      Presidential_Candidate         State  Final_Sent  \n",
       " 0              Donald Trump       Arizona          -1  \n",
       " 1              Donald Trump       Arizona          -1  \n",
       " 2              Donald Trump       Arizona           0  \n",
       " 3              Donald Trump       Arizona          -1  \n",
       " 4              Donald Trump       Arizona          -1  \n",
       " ...                     ...           ...         ...  \n",
       " 5740          Kamala Harris  Pennsylvania           1  \n",
       " 5741          Kamala Harris  Pennsylvania           1  \n",
       " 5742          Kamala Harris  Pennsylvania           1  \n",
       " 5743           Donald Trump  Pennsylvania           1  \n",
       " 5744          Kamala Harris  Pennsylvania           0  \n",
       " \n",
       " [5745 rows x 4 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data():\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(final_dataset_folder_name, exist_ok=True)\n",
    "    \n",
    "    # Define file paths\n",
    "    train_path = os.path.join(final_dataset_folder_name, 'train.csv')\n",
    "    val_path = os.path.join(final_dataset_folder_name, 'validation.csv')\n",
    "    test_path = os.path.join(final_dataset_folder_name, 'test.csv')\n",
    "    \n",
    "    # Check if split files already exist\n",
    "    if all(os.path.exists(f) for f in [train_path, val_path, test_path]):\n",
    "        train = pd.read_csv(train_path)\n",
    "        val = pd.read_csv(val_path)\n",
    "        test = pd.read_csv(test_path)\n",
    "\n",
    "        # Combine DataFrames vertically\n",
    "        df = pd.concat([train, val, test], axis=0).reset_index(drop=True)\n",
    "                \n",
    "        return train, val, test, df\n",
    "    else:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(os.path.join(final_dataset_folder_name, 'final_dataset.csv'))\n",
    "        \n",
    "        # Split data into 80% training+validation and 20% test\n",
    "        remaining, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        # Split the remaining 80% into 70% training and 10% validation (0.125 of 80% = 10% overall)\n",
    "        train, val = train_test_split(remaining, test_size=0.125, random_state=42)\n",
    "        \n",
    "        # Save splits\n",
    "        train.to_csv(train_path, index=False)\n",
    "        val.to_csv(val_path, index=False)\n",
    "        test.to_csv(test_path, index=False)\n",
    "    \n",
    "        return train, val, test, df\n",
    "\n",
    "train, val, test, full = split_data()\n",
    "\n",
    "train, val, test, full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11bd1f1-9598-4646-ad0a-aa43c9e58350",
   "metadata": {},
   "source": [
    "# Computing Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad121e53-d2dc-4afe-bf3a-25dfa335307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9941, 1.1636, 0.8422])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_class_weights(labels):\n",
    "    # Shift labels for model [-1, 0, 1] to [0, 1, 2]\n",
    "    mapped_labels = labels + 1\n",
    "    # Count how many samples we have of each class\n",
    "    class_counts = np.bincount(mapped_labels)\n",
    "    # Give higher weights to classes with fewer samples\n",
    "    weights = 1. / class_counts\n",
    "    # Normalize weights to sum to number of classes\n",
    "    weights = weights * len(class_counts) / weights.sum()\n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "# Calculate weights for each class from training data\n",
    "class_weights = compute_class_weights(train[sentiment_column_name].values)\n",
    "class_weights = class_weights.to(device)  # Move weights to GPU if available\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7a7234-8fdd-4271-877b-833dfbb85689",
   "metadata": {},
   "source": [
    "# Configure Model and Tokenizer (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de75a40e-3da8-4256-b57b-deb4fe2a1d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizer(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base DistilBERT model to use\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "# Create a custom DistilBERT model that can handle weighted loss\n",
    "class DistilBertWithWeightedLoss(DistilBertForSequenceClassification):\n",
    "    def __init__(self, config, class_weights):\n",
    "        super().__init__(config)\n",
    "        self.class_weights = class_weights # Store class weights for loss calculation\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Get model outputs without computing loss\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=None # Set to None to prevent automatic loss calculation\n",
    "        )\n",
    "        \n",
    "        # Calculate weighted loss if labels are provided (training phase)\n",
    "        if labels is not None:\n",
    "            # Create loss function with class weights\n",
    "            loss_fct = CrossEntropyLoss(weight=self.class_weights)\n",
    "            # Calculate loss using model predictions and true labels\n",
    "            loss = loss_fct(\n",
    "                outputs.logits.view(-1, self.num_labels),  # Reshape predictions\n",
    "                labels.view(-1)                            # Reshape labels\n",
    "            )\n",
    "            outputs.loss = loss  # Add loss to outputs\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# Initialize the tokenizer that will convert text to numbers\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e6d09e",
   "metadata": {},
   "source": [
    "# Define Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcdbb7d-55b2-4d28-8b6e-7cc1b40a6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_data, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a copy of eval_data to avoid modifying the original\n",
    "    results_df = eval_data.copy()\n",
    "    # Add new column for predictions\n",
    "    results_df['Predicted_Sent'] = None\n",
    "        \n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(results_df.iterrows(), total=len(results_df), desc=\"Evaluating\"):\n",
    "            # Tokenize single sentence\n",
    "            encoding = tokenizer(\n",
    "                row[sentence_column_name],\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Move inputs to device\n",
    "            input_ids = encoding['input_ids'].to(device)\n",
    "            attention_mask = encoding['attention_mask'].to(device)\n",
    "            label = torch.tensor([row[sentiment_column_name]]).to(device)\n",
    "            adjusted_label = label + 1\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(input_ids, attention_mask, labels=adjusted_label)\n",
    "            val_loss += outputs.loss.item()\n",
    "            \n",
    "            # Get prediction\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            pred = (predicted - 1).cpu().numpy()[0]\n",
    "            \n",
    "            # Store prediction in DataFrame\n",
    "            results_df.at[idx, 'Predicted_Sent'] = int(pred)\n",
    "            \n",
    "            # Store for metrics calculation\n",
    "            all_preds.append(pred)\n",
    "            all_labels.append(row[sentiment_column_name])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        'loss': val_loss / len(results_df),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1-score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b34b89",
   "metadata": {},
   "source": [
    "# Define Model Training and Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "794bb0ab-7b68-408e-830c-60e6ad40c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, train_loader, val_data, device, epochs, learning_rate):\n",
    "    # Initialize optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    val_metrics = None\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    val_accuracy = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # Set model to training mode\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Process each batch\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} Training\")\n",
    "        for batch in pbar:\n",
    "            # Move batch to GPU if available\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            adjusted_labels = labels + 1 # Shift labels for model [-1, 0, 1] to [0, 1, 2]\n",
    "\n",
    "            # Training step\n",
    "            optimizer.zero_grad() # Clear previous gradients\n",
    "            outputs = model(input_ids, attention_mask, labels=adjusted_labels) # Forward pass\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item() # Accumulate loss\n",
    "\n",
    "            # Update model weights\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights\n",
    "\n",
    "            # Update progress bar with current loss\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculate training loss for this epoch\n",
    "        current_train_loss = total_loss / len(train_loader)\n",
    "        train_loss.append(current_train_loss)\n",
    "\n",
    "        # Calculate validation loss and accuracy for this epoch\n",
    "        val_metrics, _ = evaluate_model(model, val_data, device)\n",
    "        val_loss.append(val_metrics['loss'])\n",
    "        val_accuracy.append(val_metrics['accuracy'])\n",
    "\n",
    "        print(f'Training loss: {current_train_loss}')\n",
    "        print(f'Validation metric: {val_metrics}')\n",
    "    \n",
    "    return model, {\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4d8cd",
   "metadata": {},
   "source": [
    "# Define Model Training with Hyperparameters Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e77d3-a686-4869-a66f-92e62db0c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Batch Text Data\n",
    "def create_data_loader(data, tokenizer, batch_size):\n",
    "    # Create a copy of data to avoid modifying the original\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Convert text to DistilBERT input format with progress bar\n",
    "    encodings = tokenizer(\n",
    "        data_copy[sentence_column_name].tolist(), # Convert sentences to list\n",
    "        truncation=True, # Cut texts longer than max_length\n",
    "        padding=True, # Pad texts shorter than max_length\n",
    "        max_length=128, # Maximum sequence length\n",
    "        return_tensors='pt', # Return PyTorch tensors\n",
    "        verbose=True # Show progress\n",
    "    )\n",
    "\n",
    "    # Create dataset by combining inputs and labels\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        encodings['input_ids'], # Tokenized text\n",
    "        encodings['attention_mask'], # Attention mask for padding\n",
    "        torch.tensor(data_copy[sentiment_column_name].tolist()) # Labels\n",
    "    )\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Function to Train Model with Specific Hyperparameters\n",
    "def train_model_with_hyperparameters(params, train_data, val_data, device, class_weights):\n",
    "    print(f\"Parameters: {params}\")\n",
    "\n",
    "    # Create data loaders with current batch size\n",
    "    train_loader = create_data_loader(train_data, tokenizer, params['batch_size'])\n",
    "\n",
    "    # Initialize the custom DistilBERT model\n",
    "    model = DistilBertWithWeightedLoss.from_pretrained(\n",
    "        model_name,\n",
    "        # Configure DistilBERT for classification\n",
    "        config=DistilBertForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=3,\n",
    "            output_attentions=False, # Don't output attention weights\n",
    "            output_hidden_states=False, # Don't output hidden states\n",
    "        ).config,\n",
    "        class_weights=class_weights\n",
    "    )\n",
    "    # Move model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    # Train model with current parameters\n",
    "    model, train_metric_seq = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_data,\n",
    "        device,\n",
    "        params['epochs'],\n",
    "        params['learning_rate']\n",
    "    )\n",
    "    \n",
    "    return model, train_metric_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bf97a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f1c9e-cee6-4a54-9fc9-a114f6b68833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using different values to try for each hyperparameters\n",
    "params = {\n",
    "    'hyperparameter_id': 1,\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 2,\n",
    "    'batch_size': 16\n",
    "}\n",
    "model, train_metric_seq = train_model_with_hyperparameters(params, train, val, device, class_weights)\n",
    "\n",
    "# Create Hyperparameter Directory\n",
    "model_evaluation_result_folder_name = os.path.join(model_evaluation_result_folder_name, f'Hyperparameter-{params['hyperparameter_id']}')\n",
    "os.makedirs(model_evaluation_result_folder_name, exist_ok=True)\n",
    "\n",
    "# Name of Parameters as Filename\n",
    "file_name = f'LR {params[\"learning_rate\"]}, E {params[\"epochs\"]}, BS {params[\"batch_size\"]}'\n",
    "\n",
    "# Save the model\n",
    "model_folder_name = os.path.join(model_evaluation_result_folder_name, f'{file_name} - Model')\n",
    "model.save_pretrained(model_folder_name)\n",
    "tokenizer.save_pretrained(model_folder_name)\n",
    "\n",
    "train_metric_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb6a6d3",
   "metadata": {},
   "source": [
    "# Model Validation and Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766f98c-5bde-44b7-ae75-9574d6cef804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Parameters: {params}\")\n",
    "\n",
    "# Evaluation on Test Set\n",
    "test_metrics, predicted_labels_df = evaluate_model(model, test, device)\n",
    "_, full_predicted_labels_df = evaluate_model(model, full, device)\n",
    "\n",
    "# Save Validation Metrics\n",
    "metric_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Validation Metric.csv'\n",
    ")\n",
    "pd.DataFrame(train_metric_seq).to_csv(metric_results_file_name, index=False)\n",
    "\n",
    "# Save Test Metrics\n",
    "metric_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Test Metric.csv'\n",
    ")\n",
    "pd.DataFrame([test_metrics]).to_csv(metric_results_file_name, index=False)\n",
    "\n",
    "# Save Predicted Labels\n",
    "sentiment_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Predicted Dataset.csv'\n",
    ")\n",
    "predicted_labels_df.to_csv(sentiment_results_file_name, index=False)\n",
    "\n",
    "# Save Full Predicted Labels\n",
    "full_sentiment_results_file_name = os.path.join(\n",
    "    model_evaluation_result_folder_name,\n",
    "    f'{file_name} - Full Predicted Dataset.csv'\n",
    ")\n",
    "full_predicted_labels_df.to_csv(full_sentiment_results_file_name, index=False)\n",
    "\n",
    "print(f\"Test set metrics: {test_metrics}\")\n",
    "predicted_labels_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
