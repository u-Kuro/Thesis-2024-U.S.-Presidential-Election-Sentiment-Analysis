{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import os, re, torch, ffmpeg, whisper\n",
    "import pandas as pd\n",
    "from pytubefix import YouTube, Stream\n",
    "from pytubefix.cli import on_progress\n",
    "from pytubefix.innertube import _default_clients\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(filename: str) -> str:\n",
    "    # Escape Double Quotes\n",
    "    filename = filename.replace('\"', '\\\\\"')\n",
    "\n",
    "    # Replace Invalid Characters with \"_\"\n",
    "    invalid_chars = re.compile(r'[<>:\"/\\\\|?*]')\n",
    "    sanitized_filename = invalid_chars.sub(\"_\", filename)\n",
    "\n",
    "    return sanitized_filename\n",
    "def read_unique_items_from_file(file: str) -> list:\n",
    "    if os.path.exists(file):\n",
    "        with open(file, \"r\") as f:\n",
    "            return list(set(e.strip() for e in f.readlines() if e.strip()))\n",
    "    return []\n",
    "def read_unique_items_from_csv(file: str, column: str = \"URL\") -> list:\n",
    "    if os.path.exists(file):\n",
    "        return pd.read_csv(file, encoding_errors=\"ignore\")[column].tolist()\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Names\n",
    "yt_video_links_filename = os.path.join(\"YouTube URL Collection\", \"Used URLs.csv\")\n",
    "\n",
    "# Folder Names\n",
    "video_output_path = \"Video\"\n",
    "audio_output_path = \"Audio\"\n",
    "transcription_output_path = \"Transcription\"\n",
    "\n",
    "# Boolean Flags\n",
    "remove_video = True\n",
    "remove_audio = True\n",
    "authorize_yt = False # Change to true if YouTube Detects you as a BOT\n",
    "\n",
    "# Additional Dependency Configurations\n",
    "_default_clients[\"ANDROID_MUSIC\"] = _default_clients[\"ANDROID_CREATOR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data (YouTube Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_youtube_video(video_filename: str, stream: Stream) -> tuple[str, str]:\n",
    "    # Create Video Directory\n",
    "    os.makedirs(video_output_path, exist_ok=True)\n",
    "    \n",
    "    # Set Path for Video File\n",
    "    video_file = os.path.join(video_output_path, video_filename)\n",
    "    \n",
    "    # Delete Old Existing Video File (note: to clean any corrupted file)\n",
    "    if os.path.exists(video_file):\n",
    "        os.remove(video_file)\n",
    "        \n",
    "    # Download Video File\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    print(f'Downloading (Video): {video_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    stream.download(output_path=video_output_path, filename=video_filename)\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    \n",
    "    # Return Video File and Name\n",
    "    return video_file, video_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Extraction (Video to Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_file: str, video_filename: str) -> tuple[str, str]:\n",
    "    # Create the Audio Directory\n",
    "    os.makedirs(audio_output_path, exist_ok=True)\n",
    "\n",
    "    # Set Audio File Name (\"[YouTube Video ID] [title].mp3\")\n",
    "    audio_filename = f'{os.path.splitext(video_filename)[0]}.mp3'\n",
    "\n",
    "    # Set Path for Audio File\n",
    "    audio_file = os.path.join(audio_output_path, audio_filename)\n",
    "    \n",
    "    # Delete Old Existing Audio File (note: to clean any corrupted file)\n",
    "    if os.path.exists(audio_file):\n",
    "        os.remove(audio_file)\n",
    "    \n",
    "    # Extract Audio File\n",
    "    print(f'Extracting (Audio): {audio_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    (\n",
    "        ffmpeg\n",
    "        .input(video_file)\n",
    "        .output(audio_file, format=\"mp3\", acodec=\"libmp3lame\", loglevel=\"info\")\n",
    "        .run(overwrite_output=True)\n",
    "    )\n",
    "    \n",
    "    # Return Audio File and Name\n",
    "    return audio_file, audio_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription (Audio to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_audio_to_text(audio_file: str, audio_filename: str):\n",
    "    # Create the Transcription Directory\n",
    "    os.makedirs(transcription_output_path, exist_ok=True)\n",
    "    \n",
    "    # Set Transcription File Name (\"[YouTube Video ID] [title].txt\")\n",
    "    transcription_filename = f'{os.path.splitext(audio_filename)[0]}.txt'\n",
    "    \n",
    "    # Set Path for Transcription File\n",
    "    transcription_file = os.path.join(transcription_output_path, transcription_filename)\n",
    "            \n",
    "    # Get/Download OpenAI Whisper Model\n",
    "    \"\"\" \n",
    "    Models: \n",
    "        tiny, base, small, medium, large, turbo\n",
    "    English-Only:\n",
    "        tiny.en, base.en, small.en, medium.en\n",
    "    \n",
    "    Required VRAM:              Speed:\n",
    "        1) 1GB - tiny, base         1) 10x - tiny\n",
    "        2) 2GB - small              2) 8x - turbo\n",
    "        3) 5GB - medium             3) 7x - base\n",
    "        4) 6GB - turbo              4) 4x - small\n",
    "        5) 10GB - large             5) 2x - medium\n",
    "                                    6) 1x - large\n",
    "    \n",
    "    Quote from OpenAI: \n",
    "        - The .en models for English-only applications tend to perform better, especially for the tiny.en and base.en models.\n",
    "        We observed that the difference becomes less significant for the small.en and medium.en models.\n",
    "    \n",
    "    Note: 4GB lang VRAM ko kaya small.en ginamit\n",
    "    \"\"\"  \n",
    "    print(f'Transcribing (Text): {transcription_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    model = whisper.load_model(\"small.en\", device=device)\n",
    "    \n",
    "    # Transcribe Audio File (Saves Whole Text in Memory Before Disk to Avoid Corruption)\n",
    "    result = model.transcribe(audio_file, fp16=False, verbose=False)\n",
    "    try:\n",
    "        with open(transcription_file, \"w\") as f:\n",
    "            f.write(result[\"text\"])\n",
    "    except:\n",
    "        if os.path.exists(transcription_file):\n",
    "            os.remove(transcription_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd9ef3bc55540a2a9f4be9dfe9bc044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting YouTube URLs:   0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IncompleteRead(0 bytes read): https://www.youtube.com/watch?v=A78uyTwVqo4\n",
      "\n",
      "Found YouTube Video (URL): https://www.youtube.com/watch?v=bnVWRrstv-4\n",
      "\n",
      "Downloading (Video): [bnVWRrstv-4] Harris shifts focus to 'blue wall' states.mp4\n",
      "\n",
      " ↳ |██████████████████████████████████████████████████████████████████| 100.0%\n",
      "\n",
      "Extracting (Audio): [bnVWRrstv-4] Harris shifts focus to 'blue wall' states.mp3\n",
      "\n",
      "Transcribing (Text): [bnVWRrstv-4] Harris shifts focus to 'blue wall' states.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI Laptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "\n",
      "  0%|                                                                                    | 0/27469 [00:00<?, ?frames/s]\u001b[A\n",
      " 11%|███████▌                                                                | 2904/27469 [00:11<01:39, 247.82frames/s]\u001b[A\n",
      " 11%|███████▌                                                                | 2904/27469 [00:21<01:39, 247.82frames/s]\u001b[A\n",
      " 21%|██████████████▉                                                         | 5720/27469 [00:22<01:23, 259.61frames/s]\u001b[A\n",
      " 31%|██████████████████████▏                                                 | 8476/27469 [00:33<01:15, 251.73frames/s]\u001b[A\n",
      " 31%|██████████████████████▏                                                 | 8476/27469 [00:43<01:15, 251.73frames/s]\u001b[A\n",
      " 41%|████████████████████████████▊                                          | 11128/27469 [00:47<01:12, 223.99frames/s]\u001b[A\n",
      " 51%|████████████████████████████████████▎                                  | 14056/27469 [00:59<00:57, 231.88frames/s]\u001b[A\n",
      " 51%|████████████████████████████████████▎                                  | 14056/27469 [01:11<00:57, 231.88frames/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████▌                           | 16876/27469 [01:14<00:49, 214.38frames/s]\u001b[A\n",
      " 72%|███████████████████████████████████████████████████                    | 19772/27469 [01:24<00:32, 236.20frames/s]\u001b[A\n",
      " 72%|███████████████████████████████████████████████████                    | 19772/27469 [01:42<00:32, 236.20frames/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████▊             | 22372/27469 [01:46<00:27, 182.38frames/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████▌      | 24976/27469 [01:55<00:12, 204.20frames/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████| 27469/27469 [02:04<00:00, 220.22frames/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "yt_urls = read_unique_items_from_csv(yt_video_links_filename)\n",
    "\n",
    "with tqdm(total=len(yt_urls), desc=\"Getting YouTube URLs\") as pbar:\n",
    "    for index, url in enumerate(yt_urls):        \n",
    "        try:\n",
    "            current = f'{index+1}/{len(yt_urls)}'\n",
    "    \n",
    "            # Get Video Information\n",
    "            yt = YouTube(\n",
    "                url,\n",
    "                use_oauth=authorize_yt,\n",
    "                allow_oauth_cache=authorize_yt,\n",
    "                on_progress_callback=on_progress\n",
    "            )\n",
    "            stream = yt.streams.get_audio_only()\n",
    "            video_id = yt.video_id\n",
    "            \n",
    "            # Sanitize Video File Name and Add YouTube Video ID\n",
    "            video_filename = f'[{video_id}] {sanitize_filename(stream.default_filename)}'\n",
    "            video_id_pattern_in_filename = re.compile(r'\\[(.*?)\\]')\n",
    "            \n",
    "            # Get File Name Without Extension (e.g., \".mp4\")\n",
    "            filename = os.path.splitext(video_filename)[0]\n",
    "            \n",
    "            # Skip If Transcription with YouTube ID Already Exists\n",
    "            has_transcription_file = False\n",
    "            pbar.set_description(f'Checking Existing Transcriptions [{current} File]')\n",
    "            if video_id and os.path.exists(transcription_output_path):\n",
    "                for existing_transcription_filename in os.listdir(transcription_output_path):\n",
    "                    if existing_transcription_filename == \".ipynb_checkpoints\": continue\n",
    "                    if (\n",
    "                        video_id_pattern_in_filename.search(existing_transcription_filename)\n",
    "                        and video_id_pattern_in_filename.search(existing_transcription_filename).group(1) == video_id\n",
    "                    ): \n",
    "                        has_transcription_file = True\n",
    "                        break\n",
    "            if has_transcription_file:\n",
    "                # Delete/Keep Video File\n",
    "                if remove_video:\n",
    "                    for existing_video_filename in os.listdir(video_output_path):\n",
    "                        if existing_video_filename == \".ipynb_checkpoints\": continue\n",
    "                        if (\n",
    "                            video_id_pattern_in_filename.search(existing_video_filename)\n",
    "                            and video_id_pattern_in_filename.search(existing_video_filename).group(1) == video_id\n",
    "                        ): os.remove(existing_video_filename)\n",
    "                            \n",
    "                # Delete/Keep Audio File\n",
    "                if remove_audio:\n",
    "                    for existing_audio_filename in os.listdir(audio_output_path):\n",
    "                        if existing_audio_filename == \".ipynb_checkpoints\": continue\n",
    "                        if (\n",
    "                            video_id_pattern_in_filename.search(existing_audio_filename)\n",
    "                            and video_id_pattern_in_filename.search(existing_audio_filename).group(1) == video_id\n",
    "                        ): os.remove(existing_audio_filename)\n",
    "                            \n",
    "                pbar.update(1)\n",
    "                continue\n",
    "                \n",
    "            # Log YouTube URL being Processed\n",
    "            print(\"\") # Just New Line for Better Output\n",
    "            print(f'Found YouTube Video (URL): {url}')\n",
    "            \n",
    "            # Download YouTube Video\n",
    "            pbar.set_description(f'Downloading [{current} Video] ')\n",
    "            video_file, video_filename = download_youtube_video(video_filename, stream)\n",
    "            \n",
    "            # Extract Audio from Video -> Delete/Keep Video File\n",
    "            pbar.set_description(f'Extracting [{current} Audio]')\n",
    "            audio_file, audio_filename = extract_audio_from_video(video_file, video_filename)\n",
    "            if remove_video: os.remove(video_file)\n",
    "            \n",
    "            # Transcribe Audio to Text -> Delete/Keep Audio File\n",
    "            pbar.set_description(f'Transcribing [{current} Text]')\n",
    "            transcribe_audio_to_text(audio_file, audio_filename)\n",
    "            if remove_audio: os.remove(audio_file)\n",
    "                \n",
    "            pbar.update(1)\n",
    "        except Exception as e: \n",
    "            print(f'{e}: {url}')\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "    pbar.set_description(\"Finished Data Gathering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
