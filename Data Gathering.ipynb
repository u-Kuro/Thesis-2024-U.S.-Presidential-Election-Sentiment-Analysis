{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Main Dependencies\n",
    "import os, re, ffmpeg, whisper\n",
    "from pytubefix import YouTube, Stream\n",
    "from pytubefix.cli import on_progress\n",
    "from pytubefix.innertube import _default_clients\n",
    "\n",
    "# Import Other Dependencies\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(filename: str) -> str:\n",
    "    # Escape Double Quotes\n",
    "    filename = filename.replace('\"', '\\\\\"')\n",
    "\n",
    "    # Replace Invalid Characters with \"_\"\n",
    "    invalid_chars = re.compile(r'[<>:\"/\\\\|?*]')\n",
    "    sanitized_filename = invalid_chars.sub(\"_\", filename)\n",
    "\n",
    "    return sanitized_filename\n",
    "    \n",
    "def read_unique_items_from_file(file: str) -> list:\n",
    "    with open(file, \"r\") as f:\n",
    "        return list(set(url.strip() for url in f.readlines() if url.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Names\n",
    "yt_video_links_filename = \"YouTube Video Links.txt\"\n",
    "transcript_sentences_filename = \"transcript_sentences.csv\"\n",
    "\n",
    "# Folder Names\n",
    "video_output_path = \"Video\"\n",
    "audio_output_path = \"Audio\"\n",
    "transcription_output_path = \"Transcription\"\n",
    "\n",
    "# Boolean Flags\n",
    "remove_video = True\n",
    "remove_audio = True\n",
    "\n",
    "# Additional Dependency Configurations\n",
    "_default_clients[\"ANDROID_MUSIC\"] = _default_clients[\"ANDROID_CREATOR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data (YouTube Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video(video_filename: str, stream: Stream) -> tuple[str, str]:\n",
    "    # Create Video Directory\n",
    "    os.makedirs(video_output_path, exist_ok=True)\n",
    "    \n",
    "    # Set Path for Video File\n",
    "    video_file = os.path.join(video_output_path, video_filename)\n",
    "    \n",
    "    # Delete Old Existing Video File (note: to clean any corrupted file)\n",
    "    if os.path.exists(video_file):\n",
    "        os.remove(video_file)\n",
    "        \n",
    "    # Download Video File\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    print(f'Downloading (Video): {video_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    stream.download(output_path=video_output_path, filename=video_filename)\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    \n",
    "    # Return Video File and Name\n",
    "    return video_file, video_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Extraction (Video to Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_file: str, video_filename: str) -> tuple[str, str]:\n",
    "    # Create the Audio Directory\n",
    "    os.makedirs(audio_output_path, exist_ok=True)\n",
    "\n",
    "    # Set Audio File Name (\"[YouTube Video ID] [title].mp3\")\n",
    "    audio_filename = f'{os.path.splitext(video_filename)[0]}.mp3'\n",
    "\n",
    "    # Set Path for Audio File\n",
    "    audio_file = os.path.join(audio_output_path, audio_filename)\n",
    "    \n",
    "    # Delete Old Existing Audio File (note: to clean any corrupted file)\n",
    "    if os.path.exists(audio_file):\n",
    "        os.remove(audio_file)\n",
    "    \n",
    "    # Extract Audio File\n",
    "    print(f'Extracting (Audio): {audio_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    (\n",
    "        ffmpeg\n",
    "        .input(video_file)\n",
    "        .output(audio_file, format=\"mp3\", acodec=\"libmp3lame\", loglevel=\"info\")\n",
    "        .run(overwrite_output=True)\n",
    "    )\n",
    "    \n",
    "    # Return Audio File and Name\n",
    "    return audio_file, audio_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription (Audio to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_to_text(audio_file: str, audio_filename: str):\n",
    "    # Create the Transcription Directory\n",
    "    os.makedirs(transcription_output_path, exist_ok=True)\n",
    "    \n",
    "    # Set Transcription File Name (\"[YouTube Video ID] [title].txt\")\n",
    "    transcription_filename = f'{os.path.splitext(audio_filename)[0]}.txt'\n",
    "    \n",
    "    # Set Path for Transcription File\n",
    "    transcription_file = os.path.join(transcription_output_path, transcription_filename)\n",
    "            \n",
    "    # Get/Download OpenAI Whisper Model\n",
    "    \"\"\" \n",
    "    Models: \n",
    "        tiny, base, small, medium, large, turbo\n",
    "    English-Only:\n",
    "        tiny.en, base.en, small.en, medium.en\n",
    "    \n",
    "    Required VRAM:              Speed:\n",
    "        1) 1GB - tiny, base         1) 10x - tiny\n",
    "        2) 2GB - small              2) 8x - turbo\n",
    "        3) 5GB - medium             3) 7x - base\n",
    "        4) 6GB - turbo              4) 4x - small\n",
    "        5) 10GB - large             5) 2x - medium\n",
    "                                    6) 1x - large\n",
    "    \n",
    "    Quote from OpenAI: \n",
    "        - The .en models for English-only applications tend to perform better, especially for the tiny.en and base.en models.\n",
    "        We observed that the difference becomes less significant for the small.en and medium.en models.\n",
    "    \n",
    "    Note: 4GB lang VRAM ko kaya small.en ginamit\n",
    "    \"\"\"  \n",
    "    print(f'Transcribing (Text): {transcription_filename}')\n",
    "    print(\"\") # Just New Line for Better Output\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    model = whisper.load_model(\"small.en\", device=device)\n",
    "    \n",
    "    # Transcribe Audio File (Saves Whole Text in Memory Before Disk to Avoid Corruption)\n",
    "    result = model.transcribe(audio_file, fp16=False, verbose=False)\n",
    "    try:\n",
    "        with open(transcription_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(result[\"text\"])\n",
    "    except:\n",
    "        if os.path.exists(transcription_file):\n",
    "            os.remove(transcription_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956aaad6cb46430eaff7f7b99c360580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting YouTube URLs:   0%|          | 0/269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found YouTube Video (URL): https://www.youtube.com/watch?v=P46C21DTz6A\n",
      "\n",
      "Downloading (Video): [P46C21DTz6A] Kamala Harris Touts Popular Progressive Policy During Pennsylvania Stop.mp4\n",
      "\n",
      " ↳ |█████████████████████████████████████████| 100.0%\n",
      "\n",
      "Extracting (Audio): [P46C21DTz6A] Kamala Harris Touts Popular Progressive Policy During Pennsylvania Stop.mp3\n",
      "\n",
      "Transcribing (Text): [P46C21DTz6A] Kamala Harris Touts Popular Progressive Policy During Pennsylvania Stop.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI Laptop\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "\n",
      "  0%|                                        | 0/48032 [00:00<?, ?frames/s]\u001b[A\n",
      "  6%|█▋                          | 2882/48032 [00:08<02:18, 325.63frames/s]\u001b[A\n",
      " 11%|███▏                        | 5514/48032 [00:14<01:52, 376.90frames/s]\u001b[A\n",
      " 18%|████▉                       | 8434/48032 [00:21<01:35, 414.73frames/s]\u001b[A\n",
      " 23%|██████▎                    | 11270/48032 [00:29<01:38, 374.60frames/s]\u001b[A\n",
      " 29%|███████▉                   | 14166/48032 [00:37<01:30, 372.31frames/s]\u001b[A\n",
      " 36%|█████████▌                 | 17118/48032 [00:45<01:22, 376.64frames/s]\u001b[A\n",
      " 42%|███████████▏               | 19990/48032 [00:51<01:07, 413.25frames/s]\u001b[A\n",
      " 47%|████████████▋              | 22498/48032 [00:58<01:06, 386.88frames/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "yt_urls = read_unique_items_from_file(yt_video_links_filename)\n",
    "\n",
    "with tqdm(total=len(yt_urls), desc=\"Getting YouTube URLs\") as pbar:\n",
    "    for index, url in enumerate(yt_urls):        \n",
    "        try:\n",
    "            current = f'{index+1}/{len(yt_urls)}'\n",
    "    \n",
    "            # Get Video Information\n",
    "            yt = YouTube(url, on_progress_callback=on_progress)\n",
    "            stream = yt.streams.get_audio_only()\n",
    "            # Sanitize Video File Name and Add YouTube Video ID\n",
    "            video_filename = f'[{yt.video_id}] {sanitize_filename(stream.default_filename)}'\n",
    "            \n",
    "            # Get File Name Without Extension (e.g., \".mp4\")\n",
    "            filename = os.path.splitext(video_filename)[0]\n",
    "            \n",
    "            # Skip If Transcription Already Exists\n",
    "            transcription_exists = False\n",
    "            pbar.set_description(f'Checking Existing Transcriptions (Video {current})')\n",
    "            if os.path.exists(transcription_output_path):\n",
    "                transcription_filename = f'{filename}.txt'\n",
    "                for existing_transcription_filename in os.listdir(transcription_output_path):\n",
    "                    if existing_transcription_filename == transcription_filename:\n",
    "                        existing_transcription_path = os.path.join(transcription_output_path, existing_transcription_filename)\n",
    "                        if os.path.exists(existing_transcription_path):\n",
    "                            transcription_exists = True\n",
    "            if transcription_exists:\n",
    "                # Delete/Keep Video File\n",
    "                if remove_video:\n",
    "                    video_file = os.path.join(video_output_path, video_filename)\n",
    "                    if os.path.exists(video_file):\n",
    "                        os.remove(video_file)\n",
    "                        \n",
    "                # Delete/Keep Audio File\n",
    "                if remove_audio:\n",
    "                    audio_filename = f'{filename}.mp3'\n",
    "                    audio_file = os.path.join(audio_output_path, audio_filename)\n",
    "                    if os.path.exists(audio_file):\n",
    "                        os.remove(audio_file)\n",
    "                        \n",
    "                pbar.update(1)\n",
    "                continue\n",
    "    \n",
    "            # Log YouTube URL being Processed\n",
    "            print(\"\") # Just New Line for Better Output\n",
    "            print(f'Found YouTube Video (URL): {url}')\n",
    "            \n",
    "            # Download YouTube Video\n",
    "            pbar.set_description(f'Downloading (Video {current}) ')\n",
    "            video_file, video_filename = download_youtube_video(video_filename, stream)\n",
    "            \n",
    "            # Extract Audio from Video -> Delete/Keep Video File\n",
    "            pbar.set_description(f'Extracting (Audio {current})')\n",
    "            audio_file, audio_filename = extract_audio_from_video(video_file, video_filename)\n",
    "            if remove_video: os.remove(video_file)\n",
    "            \n",
    "            # Transcribe Audio to Text -> Delete/Keep Audio File\n",
    "            pbar.set_description(f'Transcribing (Text {current})')\n",
    "            transcribe_audio_to_text(audio_file, audio_filename)\n",
    "            if remove_audio: os.remove(audio_file)\n",
    "                \n",
    "            pbar.update(1)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            pbar.update(1)\n",
    "    pbar.set_description(\"Finished Data Gathering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
